<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Theme Suggester ‚Äì ONNX WebGPU</title>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/onnxruntime-web/1.18.0/ort.webgpu.min.js"></script>
  <style>
    * { margin:0; padding:0; box-sizing:border-box; }
    body {
      font-family:'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);
      min-height:100vh; display:flex; align-items:center; justify-content:center;
      padding:20px;
    }
    .container {
      background:white; border-radius:16px; box-shadow:0 20px 60px rgba(0,0,0,0.3);
      max-width:800px; width:100%; padding:40px;
    }
    h1 { color:#333; margin-bottom:10px; font-size:2em; }
    .subtitle { color:#666; margin-bottom:20px; font-size:0.9em; }
    .status { padding:15px; border-radius:8px; margin-bottom:20px; font-weight:500;
      display:flex; align-items:center; gap:10px; }
    .status.info { background:#e3f2fd; color:#1976d2; border-left:4px solid #1976d2; }
    .status.success { background:#e8f5e9; color:#388e3c; border-left:4px solid #388e3c; }
    .status.error { background:#ffebee; color:#c62828; border-left:4px solid #c62828; }
    .spinner {
      border:3px solid #f3f3f3; border-top:3px solid #667eea; border-radius:50%;
      width:20px; height:20px; animation:spin 1s linear infinite;
    }
    @keyframes spin { 0%{transform:rotate(0deg);} 100%{transform:rotate(360deg);} }
    textarea {
      width:100%; padding:12px; border:2px solid #ddd; border-radius:8px;
      font-size:14px; min-height:100px; resize:vertical; margin-bottom:20px;
    }
    button {
      background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);
      color:white; border:none; padding:14px 32px; border-radius:8px;
      font-size:16px; cursor:pointer; width:100%;
    }
    .output { margin-top:20px; padding:20px; background:#f7f7f7;
      border-radius:8px; display:none; white-space:pre-wrap; }
  </style>
</head>

<body>
<div class="container">
  <h1>üé® Theme Suggester</h1>
  <p class="subtitle">Qwen2.5 ‚Äì ONNX INT8 ‚Äì WebGPU Inference</p>

  <div id="status" class="status info">
    <div class="spinner"></div>
    <span>Checking WebGPU support...</span>
  </div>

  <textarea id="input-text" placeholder="Example: Suggest a theme for a healthcare website..."></textarea>
  <button id="run-btn" disabled>Run Inference</button>

  <div id="output" class="output"></div>
</div>

<script type="module">
  import { AutoTokenizer } from "https://cdn.jsdelivr.net/npm/@xenova/transformers@3.2.0/dist/transformers.esm.js";

  const modelUrl =
    "https://huggingface.co/anand-ai/theme-suggester-onnx-int8/resolve/main/model_quantized.onnx";

  const tokenizerBase =
    "https://huggingface.co/anand-ai/theme-suggester-onnx-int8/resolve/main/";

  let tokenizer;
  let session;

  const statusEl = document.getElementById("status");
  const runBtn = document.getElementById("run-btn");
  const outputEl = document.getElementById("output");

  function setStatus(msg, type = "info", spinner = false) {
    statusEl.className = `status ${type}`;
    statusEl.innerHTML = spinner
      ? `<div class="spinner"></div><span>${msg}</span>`
      : `<span>${msg}</span>`;
  }

  async function checkWebGPU() {
    if (!navigator.gpu) {
      setStatus("‚ùå WebGPU not supported. Use Chrome/Edge 113+.", "error");
      return false;
    }
    setStatus("‚úì WebGPU supported!", "success");
    return true;
  }

  async function loadTokenizer() {
    setStatus("Loading tokenizer...", "info", true);
    tokenizer = await AutoTokenizer.fromPretrained(tokenizerBase);
    setStatus("‚úì Tokenizer loaded", "success");
  }

  async function loadModel() {
    setStatus("Loading ONNX Model‚Ä¶", "info", true);

    ort.env.wasm.numThreads = 1;

    session = await ort.InferenceSession.create(modelUrl, {
      executionProviders: ["webgpu"],
      graphOptimizationLevel: "all"
    });

    console.log("Inputs:", session.inputNames);
    console.log("Outputs:", session.outputNames);

    setStatus("‚úì Model loaded!", "success");
    runBtn.disabled = false;
  }

  function createInitialKV() {
    const layers = 24;
    const num_kv_heads = 2;
    const head_dim = 64;
    const b = 1;
    const past = 0;

    const kv = {};
    for (let i = 0; i < layers; i++) {
      kv[`past_key_values.${i}.key`] =
        new ort.Tensor("float32", new Float32Array(b * num_kv_heads * past * head_dim),
          [1, num_kv_heads, past, head_dim]);

      kv[`past_key_values.${i}.value`] =
        new ort.Tensor("float32", new Float32Array(b * num_kv_heads * past * head_dim),
          [1, num_kv_heads, past, head_dim]);
    }
    return kv;
  }

  async function generate(prompt, maxNewTokens = 80) {
    outputEl.style.display = "none";
    setStatus("Running inference...", "info", true);

    const encoded = await tokenizer.encode(prompt);
    let inputIds = encoded.ids.map(i => BigInt(i));

    let pos = 0n;
    let kv = createInitialKV();

    const generated = [...inputIds];

    for (let step = 0; step < maxNewTokens; step++) {
      const inputTensor = new ort.Tensor("int64",
        BigInt64Array.from(inputIds), [1, inputIds.length]);

      const attnTensor = new ort.Tensor("int64",
        BigInt64Array.from(inputIds.map(_ => 1n)), [1, inputIds.length]);

      const posTensor = new ort.Tensor("int64",
        BigInt64Array.from(inputIds.map(() => pos++)), [1, inputIds.length]);

      const feeds = {
        input_ids: inputTensor,
        attention_mask: attnTensor,
        position_ids: posTensor,
        ...kv
      };

      const out = await session.run(feeds);
      const logits = out.logits.data;

      const vocab = logits.length / inputIds.length;
      const last = logits.slice((inputIds.length - 1) * vocab);

      let maxVal = last[0], maxIdx = 0;
      for (let i = 1; i < last.length; i++) {
        if (last[i] > maxVal) {
          maxVal = last[i];
          maxIdx = i;
        }
      }

      const nextTok = BigInt(maxIdx);
      generated.push(nextTok);

      if (nextTok === BigInt(151645)) break; // eos

      inputIds = [nextTok];

      // Update KV
      for (let i = 0; i < 24; i++) {
        kv[`present.${i}.key`] = out[`present.${i}.key`];
        kv[`present.${i}.value`] = out[`present.${i}.value`];
      }
    }

    const decoded = await tokenizer.decode(generated.map(n => Number(n)));
    setStatus("‚úì Done!", "success");
    outputEl.textContent = decoded;
    outputEl.style.display = "block";
  }

  document.getElementById("run-btn").addEventListener("click", () => {
    const text = document.getElementById("input-text").value.trim();
    if (!text) return setStatus("‚ö† Enter a prompt", "warning");
    generate(text);
  });

  (async () => {
    if (await checkWebGPU()) {
      await loadTokenizer();
      await loadModel();
    }
  })();
</script>
</body>
</html>
