<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Theme Suggester - ONNX WebGPU Demo</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/onnxruntime-web/1.17.1/ort.webgpu.min.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            padding: 20px;
        }
        
        .container {
            background: white;
            border-radius: 16px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
            max-width: 800px;
            width: 100%;
            padding: 40px;
        }
        
        h1 {
            color: #333;
            margin-bottom: 10px;
            font-size: 2em;
        }
        
        .subtitle {
            color: #666;
            margin-bottom: 30px;
            font-size: 0.9em;
        }
        
        .status {
            padding: 15px;
            border-radius: 8px;
            margin-bottom: 20px;
            font-weight: 500;
            display: flex;
            align-items: center;
            gap: 10px;
        }
        
        .status.info {
            background: #e3f2fd;
            color: #1976d2;
            border-left: 4px solid #1976d2;
        }
        
        .status.success {
            background: #e8f5e9;
            color: #388e3c;
            border-left: 4px solid #388e3c;
        }
        
        .status.error {
            background: #ffebee;
            color: #c62828;
            border-left: 4px solid #c62828;
        }
        
        .status.warning {
            background: #fff3e0;
            color: #e65100;
            border-left: 4px solid #e65100;
        }
        
        .spinner {
            border: 3px solid #f3f3f3;
            border-top: 3px solid #667eea;
            border-radius: 50%;
            width: 20px;
            height: 20px;
            animation: spin 1s linear infinite;
        }
        
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        
        .input-group {
            margin-bottom: 20px;
        }
        
        label {
            display: block;
            color: #555;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        textarea {
            width: 100%;
            padding: 12px;
            border: 2px solid #ddd;
            border-radius: 8px;
            font-size: 14px;
            font-family: inherit;
            resize: vertical;
            min-height: 100px;
            transition: border-color 0.3s;
        }
        
        textarea:focus {
            outline: none;
            border-color: #667eea;
        }
        
        button {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border: none;
            padding: 14px 32px;
            border-radius: 8px;
            font-size: 16px;
            font-weight: 600;
            cursor: pointer;
            transition: transform 0.2s, box-shadow 0.2s;
            width: 100%;
        }
        
        button:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 8px 20px rgba(102, 126, 234, 0.4);
        }
        
        button:disabled {
            opacity: 0.6;
            cursor: not-allowed;
        }
        
        .output {
            margin-top: 20px;
            padding: 20px;
            background: #f8f9fa;
            border-radius: 8px;
            border: 2px solid #e9ecef;
            display: none;
        }
        
        .output.show {
            display: block;
        }
        
        .output h3 {
            color: #333;
            margin-bottom: 12px;
        }
        
        .output-content {
            color: #555;
            line-height: 1.6;
            white-space: pre-wrap;
            word-wrap: break-word;
        }
        
        .model-info {
            background: #f8f9fa;
            padding: 15px;
            border-radius: 8px;
            margin-bottom: 20px;
            font-size: 0.85em;
            color: #666;
        }
        
        .model-info strong {
            color: #333;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ðŸŽ¨ Theme Suggester</h1>
        <p class="subtitle">ONNX INT8 Model with WebGPU Acceleration</p>
        
        <div id="status" class="status info">
            <div class="spinner"></div>
            <span>Checking WebGPU support...</span>
        </div>
        
        <div class="model-info">
            <strong>Model:</strong> anand-ai/theme-suggester-onnx-int8<br>
            <strong>Base:</strong> Qwen2.5-0.5B-Instruct (Fine-tuned on 20k samples)<br>
            <strong>Format:</strong> ONNX INT8 Quantized
        </div>
        
        <div class="input-group">
            <label for="input-text">Enter your prompt:</label>
            <textarea id="input-text" placeholder="Example: I want a theme for a tech startup website..."></textarea>
        </div>
        
        <button id="run-btn" disabled>Run Inference</button>
        
        <div id="output" class="output">
            <h3>Output:</h3>
            <div class="output-content" id="output-content"></div>
        </div>
    </div>

    <script>
        let session = null;
        let tokenizer = null;
        const modelUrl = 'https://huggingface.co/anand-ai/theme-suggester-onnx-int8/resolve/main/model_quantized.onnx';
        
        const statusEl = document.getElementById('status');
        const runBtn = document.getElementById('run-btn');
        const inputText = document.getElementById('input-text');
        const outputEl = document.getElementById('output');
        const outputContent = document.getElementById('output-content');
        
        function updateStatus(message, type = 'info', showSpinner = false) {
            statusEl.className = `status ${type}`;
            statusEl.innerHTML = showSpinner 
                ? `<div class="spinner"></div><span>${message}</span>`
                : `<span>${message}</span>`;
        }
        
        async function checkWebGPU() {
            if (!navigator.gpu) {
                updateStatus('âŒ WebGPU is not supported in this browser. Please use Chrome 113+ or Edge 113+', 'error');
                return false;
            }
            
            try {
                const adapter = await navigator.gpu.requestAdapter();
                if (!adapter) {
                    updateStatus('âŒ No WebGPU adapter found', 'error');
                    return false;
                }
                updateStatus('âœ“ WebGPU is supported and available', 'success');
                return true;
            } catch (e) {
                updateStatus(`âŒ WebGPU error: ${e.message}`, 'error');
                return false;
            }
        }
        
        async function loadModel() {
            try {
                updateStatus('Loading model from Hugging Face...', 'info', true);
                
                // Configure ONNX Runtime to use WebGPU
                ort.env.wasm.numThreads = 1;
                ort.env.wasm.simd = true;
                
                session = await ort.InferenceSession.create(modelUrl, {
                    executionProviders: ['webgpu'],
                    graphOptimizationLevel: 'all'
                });
                
                updateStatus('âœ“ Model loaded successfully!', 'success');
                runBtn.disabled = false;
                
                console.log('Input names:', session.inputNames);
                console.log('Output names:', session.outputNames);
                
            } catch (error) {
                updateStatus(`âŒ Error loading model: ${error.message}`, 'error');
                console.error('Model loading error:', error);
            }
        }
        
        // Simple tokenizer (you'll need to adapt this to match your model's tokenizer)
        function simpleTokenize(text) {
            // This is a placeholder - you should implement proper tokenization
            // For Qwen2.5, you'd typically need the actual tokenizer
            const tokens = text.split(' ').map((word, idx) => idx + 1);
            return new BigInt64Array(tokens);
        }
        
        async function runInference() {
            if (!session) {
                updateStatus('âŒ Model not loaded', 'error');
                return;
            }
            
            const input = inputText.value.trim();
            if (!input) {
                updateStatus('âš ï¸ Please enter some text', 'warning');
                return;
            }
            
            try {
                runBtn.disabled = true;
                updateStatus('Running inference...', 'info', true);
                outputEl.classList.remove('show');
                
                // Tokenize input (this is simplified - adapt to your model's needs)
                const inputIds = simpleTokenize(input);
                
                // Create input tensor
                const inputTensor = new ort.Tensor('int64', inputIds, [1, inputIds.length]);
                
                // Run inference
                const feeds = {};
                feeds[session.inputNames[0]] = inputTensor;
                
                const startTime = performance.now();
                const results = await session.run(feeds);
                const inferenceTime = (performance.now() - startTime).toFixed(2);
                
                // Get output
                const output = results[session.outputNames[0]];
                
                updateStatus(`âœ“ Inference completed in ${inferenceTime}ms`, 'success');
                
                // Display results
                outputContent.textContent = `Output shape: ${output.dims}\n\nRaw output (first 20 values):\n${Array.from(output.data.slice(0, 20)).join(', ')}...`;
                outputEl.classList.add('show');
                
            } catch (error) {
                updateStatus(`âŒ Inference error: ${error.message}`, 'error');
                console.error('Inference error:', error);
            } finally {
                runBtn.disabled = false;
            }
        }
        
        runBtn.addEventListener('click', runInference);
        
        // Initialize
        (async () => {
            const webgpuSupported = await checkWebGPU();
            if (webgpuSupported) {
                await loadModel();
            }
        })();
    </script>
</body>
</html>
